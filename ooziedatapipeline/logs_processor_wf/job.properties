# hadoop cluster configuration params


nameNode=hdfs://quickstart.cloudera:8020
# Yarn resourceManager and its port number
jobTracker=quickstart.cloudera:8032
# If your cluster has Job tracker use below
# jobTracker=localhost:8021

user=cloudera
queueName=default

SCHEMA_NAME=default
hiveConfigSiteXml=conf/hive-site.xml
hiveConfigDefaultXml=conf/hive-default.xml

applicationRoot=${nameNode}/user/${user}/oozie/apps/logs_processor/lib
dataDir=${nameNode}/user/${user}/workshop/data
hiveDataDir=hdfs://quickstart.cloudera/user/cloudera/workshop/data


oozie.use.system.libpath=true
# oozie.libpath=${nameNode}/user/oozie/share/lib

LOGSPROCESSOR_PIG_OUTPUTPATH=${dataDir}/output/processlogs/pigoutput
LOGSPROCESSOR_PIG_INPUTPATH=${hiveDataDir}/output/processlogs/output


LOGSPROCESSOR_MAPREDUCE_INPUTPATH=${dataDir}/input/processlogs
LOGSPROCESSOR_MAPREDUCE_OUTPUTPATH=${dataDir}/output/processlogs/output

# Workflow starting point
oozie.wf.application.path=${nameNode}/user/${user}/oozie/apps/logs_processor/workflow-master.xml

# To run a workflow periodically, use a Coordinator. 
# Uncomment below steps and comment oozie.wf.application.path entry to run Coordinator.

# coordstartTime=2015-02-19T18:40Z
# coordendTime=2020-04-08T18:40Z
# coordTimeZone=GMT
# coordProcessName=logs_processor_workflow

# workflowRoot=${nameNode}/user/${user}/oozie/apps/logs_processor
# oozie.coord.application.path=${workflowRoot}/coordinator
# wfPath=${workflowRoot}/workflow-master.xml

